# Das Toccarion Projekt

Zusammen mit der Kinder-Musik-Welt Toccarion, ein Projekt der Sigmund Kiener Stiftung 
und dem Festspielhaus Baden-Baden, entstand die Idee folgendes Spiel zu entwickeln und 
zumindest teilweise zu realisieren. Das Toccarion bietet Kindern die Möglichkeit, 
spielerisch mit der Musik in Kontakt zu kommen. Dazu sind die Räume des Veranstalters 
thematisch unterteilt in denen die Kinder mal mehr und mal weniger frei explorieren 
können. Eine sehr freie Station erlaubt es den Kindern, aus jeden in diesem Raum 
vorhandenen Instrumenten eines (oder nacheinander auch mehrere) zu wählen und nach 
einer kurzen Einweisung seitens der musikalischen Betreuerin, frei zu musizieren. 
Auch digital gestützte, musikalische Spiele sind vorhanden. 

Unsere Aufgabe ist es, ein auf der Frontseite des Gebäudes befindliches Panel 
dergestalt zu modifizieren, dass es Passanten möglich ist, ein Spiel vor dem Panel zu 
spielen. Ziel ist es, Menschen vor Ort zu Informieren und für das Toccarion zu 
begeistern. Im Panel befindet sich ein 55 Zoll großer Bildschirm mit Touchfunktion.
Außerdem ist neben dem Bildschirm eine Pinnwand vorhanden, die das aktuelle Programm 
beinhaltet.


Fig. 1: Das Panel vor dem Toccarion	

# Einschränkungen

Das Panel befindet sich im freien, die Interaktion der Passanten erfolgt also unüberwacht. 
Um Diebstahl zu vermeiden und natürlich auch aus witterungsbedingten Umständen, sind 
Eingaben mittels Controller nicht möglich. Innerhalb des Panels befindet sich ein Windows 
PC, der für die Anzeige zuständig ist. Aufgrund dieser Umstände bietet sich die Kinect 
von Microsoft an, als Eingabegerät zu fungieren. Sie ist klein genug um unter oder auf 
dem Panel diebstahl- und witterungsgeschützt angebracht werden zu können.  Eine Eingabe 
mittels des Touchscreens wäre zwar denkbar, aber da die Zielgruppe Kinder jeden Alters 
sind, wäre die Erreichbarkeit (Höhe des Touchscreens) nicht immer gewährleistet. Aus 
diesem Grund wurde die Kinect und nicht das Touchpanel als Eingabemedium gewählt.

Die Spiele dürfen vom zeitlichen Rahmen her nicht zu lange dauern, da sie zum einen nur 
einen Vorgeschmack auf das Toccarion bieten sollen und zum anderen, darf es die Passanten 
nicht zu lange beschäftigen. Der zweite Aspekt ist besonders bedeutend, da die 
Hauptzielgruppe Kinder sind und diese oft mit Ihren Eltern und nicht allein unterwegs sind.
Da die Eltern als Entscheidungsträger fungieren, darf das Spiel die Kinder nicht so lange 
beschäftigen, als dass es den Eltern negativ im Gedächtnis bleibt. Als Beispiel sei hier 
eine Mutter aufgeführt, die einen Termin wahrnehmen muss, sich aber nun in zeitlichen 
Bedrängnis befindet, da das eigene Kind zu lange vor dem Panel spielte und nicht davon los 
kam, weil es das laufende Spiel nicht unterbrechen wollte.


Fig. 2: Zeitmanagement


# Konzeptionsphase

In der Konzeptionsphase entstanden drei Spielideen die wir hier vorstellen möchten.

## Der manische Dirigent (D-irre-gent)
Dieses Spiel nutzt die Geschwindigkeitserkennung, die mit der Kinect möglich ist und erfüllt 
den im Innenraum des Toccarion aufgeworfenen Traum, die Geschwindigkeit des Orchesters auch 
selbst lenken zu können.
Spielerzahl: 1


Fig. 3: Der manische Dirigent	

Visuelle Elemente
• 	Die rechte Dirigierhand mit Dirigierstab
• 	Die im Logo implizierten Bubbel
• 	Evtl. kleine visuelle Balken am unteren Bildschirmrand, 
  	die die Bubbel nach oben katapultieren.

Akustische Elemente
• 	Verschiedene passende Musik-Stücke im .midi Datei-Format
• 	Passende Soundfonts für die verschiedenen Stücke

In dieser Spielvariante wird der vor dem Bildschirm stehende Spieler selbst zum Dirigenten. 
Er kann durch die Geschwindigkeit seiner Gesten die Geschwindigkeit der Musik beeinflussen.

Visuell ist dabei eine Dirigierhand mit Dirigierstab zu sehen. Aus der Spitze des Stabes werden 
zauberstabsähnlich die bereits eingeführten Bubbel erzeugt. Diese Bubbel fallen an den unteren 
Bildschirmrand, wo sie je nach Geschwindigkeit der Musik nach oben katapultiert werden und so 
miteinander interagieren, voneinander abprallen und durch den Bildschirm herumhüpfen. Je schneller 
man dirigiert, desto mehr Bubbel werden erzeugt. Das beeinflussen der Musik ohne 
Klanghöhenveränderung ist möglich mit den für dieses Spiel eingesetzten .midi-Dateien.




## Das magische Orchester
Diese Spielvariante ist auch wieder eine Variante des im Innenraum installierten Spiels, in der 
der Spieler dieses mal auf die verschiedenen Orchester-Regionen fokussiert, die er im Rahmen 
seines Dirigats beeinflussen kann.
Spielerzahl: 1

Fig. 4: Das magische Orchester

Visuelle Elemente:
• Die rechte Dirigierhand mit Dirigierstab
• Die im Logo implizierten Bubbel, gruppiert nach Instrumentengruppen

Akustische Elemente
• Musikstücke, die in verschiedenen Instrumentengruppen-Varianten aufgenommen und übereinanderlegbar sind. 

Als Dirigent holt man durch seine dirigier-Gesten die verschiedenen Instrumentengruppen aus dem Orchester heraus.

Der Bildschirm ist am Anfang schwarz. Zu sehen sind nur zwei dirigierbereite Hände, davon die Rechte mit 
Dirigierstab. Wenn man seine Hände bewegt, erkennt man, dass man farbige Bubbel aus den verschiedenen Bereichen 
des Bildschirms hervorholen kann. Je mehr man das tut, desto farbiger wird auch die Klangfarbe des Stückes, 
indem mehr und mehr Instrumente dem Stück hinzugefügt werden. Die Bubbel sind so angeordnet, wie auch ein
reales Orchester sitzt.

Fig. 5: Farbcodierung beim manischen Dirigenten

## Das amorphe Instrument
Dieses Spiel nutzt die Gestenerkennung in der Kinect, um Kindern die körperliche Freude am Spielen von 
Instrumenten näherzubringen. 
Spielerzahl: 1-3


Fig. 6: Das amorphe Instrument

Visuelle Elemente:
• Eine amorphe Bubbel, die sich in verschiedene Instrumente verformen kann
• Mindestens 5 verschiedene Instrumente Akustische Elemente
• Musikstücke, die mit verschiedenen (vorher festgelegten) Einzelinstrumenten aufgenommen und übereinandergelegt werden können. 

In diesem Spiel können die Spieler durch simple Gesten die Instrumente nachspielen, auf die sie Lust haben. Dabei sind zwei Varianten denkbar, von denen die erste technisch wesentlich einfacher umzusetzen ist.

### Nachspielen
Das jeweilige Instrument wird angezeigt und der bzw. die Spieler müssen versuchen, die richtige Geste dazu zu spielen. Je besser ihnen das gelingt, desto intensiver wird die Farbe des dargestellten Instruments, desto stärker tanzt es auf dem Bildschirm mit und desto besser ist die Melodie des Instrumentes zu hören.

### Selbst entscheiden
Je nachdem, welche Geste vor dem Bildschirm dargestellt wird, wird das jeweilige erkannte Instrument auf dem Bildschirm angezeigt und mit einer Tonspur abgespielt. (Hier würde als Basis auch ohne Input eine Grundmelodie im Hintergrund abgespielt werden.) Bei mehreren Spielern kommen auch mehr Instrumente dazu.

# Hardware

Neben dem bereits erwähnten 55 Zoll Panel und dem Windows PC kommt nicht der Kinect Sensor der XBox 360, sondern der Kinect Sensor der XBox One zum Einsatz.

Fig. 7: XBox One - Kinect Sensor

Zusätzlich zum Sensor ist ein Adapter notwendig, der es ermöglicht, die Kinect an einem PC anzuschließen.

Fig. 8: XBox One - Kinect Adapter


# Software
Da die Entwickler des Teams bereits mit der Spieleengine Unity 5 Erfahrung gesammelt haben, wurde beschlossen das Spiel in eben dieser Engine umzusetzen. Neben der Spieleengine wird das Software Develompent Kit (SDK) in der Vesion 2.0 für die Kinect benötigt. Wesentlichen Bestandteil des Kinect SDK ist das Kinect Studio sowie der Visual Gesture Builder. Im Kinect Studio können Bewegungen über die Kinect aufgezeichnet werden. Dies ist notwendig, um Gesten, Bewegungen, Posen etc. zu lernen. Wurden die Aufzeichnungen abgeschlossen kann mit den Hilfe des Visual Gesture Buildes eine Bibliothek erzeugt werden, die später in Unity eingebunden werden kann.


Fig. 9: Kinect Studio und Visual Gesture Builder
# Umsetzung

## Erzeugung der Erkennungsbibliothek
Wie bereits beschrieben, ist es notwendig, mittels des Visual Gesture Builders einen Erkenner zu bauen. Dazu haben wir einige Tests mit Erwachsenen durchgeführt. Im ersten Schritt schien es auch so zu funktionieren wie geplant. Als Problem stellte sich die Körpergröße heraus, da zur Zielgruppe nicht nur Erwachsene gehören. Entsprechend muss der Erkenner angepasst werden. Erst versuchten wir, Erwachsene und Kinder in einem Erkenner unter zu bringen, die Ergebnisse waren aber deutlich schlechter als die der ersten Versuche. Also galt es, zwei dedizierte Erkenner zu erstellen die jeweils auf eine Zielgruppe spezialisiert sind. 

### Rohmaterial Kinder und Erwachsene
Um genügend Material für den Erkenner zu bekommen, vereinbarten wir einen Termin mit der Pestalozzi Schule in Durlach. Mit den Schülern einer 2. Klasse arbeiteten wir einen Vormittag zusammen, um die Bewegungen verschiedener Instrumente aufzuzeichnen. Die Kinder waren von dem Prozess der Erfassung der Bewegungen sehr angetan. Auch die Beschreibung des Spiels stieß auf ein reges Interesse der Klasse. Probanden für den Erwachsenen-Erkenner gab es in den eigenen Reihen genug, so dass es nicht nötig war, dritte mit in den Prozess einzubeziehen.

### Merkmalsextraktion und Lernen
Die vom Kinect Studio aufgezeichneten Daten liefern neben Farbinformationen auch ein Infrarot-Bild sowie Tiefeninformationen und den daraus extrahierten Skelette der erkannten Personen im Bild.


Fig. 10: Tiefeninformation mit extrahiertem Skelett

Da es pro Person nur eine Aufzeichnung gibt, in der alle Instrumente nacheinander für jeweils 30 Sekunden gespielt werden, muss im Visual Gesture Builder der Abschnitt mit dem aktuell zu lernenden Instrument markiert werden. Je nach Anzahl der Rohmaterialien ist dieser Prozess sehr Zeitaufwändig da er nicht automatisiert werden kann. Zur einfacheren Unterscheidung der Instrumente, mussten die Probanden zwischen den Instrumenten die s.g. T-Pose einnehmen.

Im Visual Gesture Builder sind diverse Parameter notwendig, um eine gute Erkennung gewährleisten zu können. Die Einstellungen die wir vorgenommen haben sind in Fig. 11 zu sehen.

Fig. 11: Einstellungen für den Visual Gesture Builder - das Skelett zeigt die T-Pose

## Anpassung der Kinect API an Unity
Um auf die Kinect API von Unity aus zugreifen zu können, war eine Anpassung notwendig. Diese geschah hauptsächlich aus dem Grund, da nur eine veraltete Version der API in verschiedenen Repositories vorlag, genügte eine Anpassung und keine komplette Neuentwicklung. Außerdem ist aufgrund der Eigenheiten von Unity eine Integration der API in ein GameObject (GestureSourceManager) notwendig. Mehr Details dazu im Abschnitt 6.3.4. Code.

## Amorphes Instrument - Aufbau
Wie in Abschnitt 3.3. beschrieben, ist diese Variante auf mehrere Spiele Spieler ausgelegt. Im vorliegenden Fall auf drei Spieler, es kann bei Bedarf auf bis zu fünf Spieler erweitert werden.

### Szenen
Die Szenerie des Spiels ist aufgeteilt in zwei Element. Zum einen das Intro, in dem das Toccarion-Logo zur wabernden Sphäre transformiert und zum anderen ein spielendes Instrument. Als Instrumente sind zum aktuellen Zeitpunkt Geige, Gitarre, Harfe, Trommel, Trompete und Flöte implementiert.

Fig. 12: Instrumente

#### Intro
Das Intro zeigt zu Beginn das Toccarion-Logo, wird eine Person vor der Kinect erkannt, transformiert das Logo zur Sphäre. Für einen Zeitraum von 10 Sekunden können nun weitere Personen dazu kommen, diese werden automatisch erkannt und als Spieler hinzugefügt. Sind die 10 Sekunden abgelaufen, startet das eigentliche Spiel.

Fig. 13: Transformation Logo zu Sphäre

#### Play<Insert Instrument>
Jedem Spieler wird eine Position zugeteilt die durch eine Sphäre repräsentiert wird. Nun können die Spieler durch die richtige Bewegung des jeweiligen Instruments, dieses zum erklingen bringen.

### Animator
Im Animator wird festgelegt, wie zwischen den Sphären und den Instrumenten gewechselt wird. Dazu gibt es zu jedem Instrument eine Animation von der Sphäre zum Instrument, vom Instrument zur Sphäre und das jeweilige Instrument im spielenden Zustand. Für jeden Spieler wird eine andere Einstiegssequenz gewählt, so dass die Sphären nicht im “gleichtakt” wabern.

Fig. 13: Animator

### Quelltext
Dieser Abschnitt soll wichtige Klassen und Code-Elemente erläutern, sollte aber nicht als alleinige Grundlage herangezogen werden. Alle wichtigen Informationen befinden sich im Quelltext, so dass dieser Abschnitt als ergänzend betrachtet werden muss.

#### GestureSourceManager
GestureSourceManager erkennt ein bis drei Spieler und deren Gesten, die die Spieler gerade ausführen. Jeder Frame wird evaluiert, um einen Konfidenzwert pro Instrument zu ermitteln. Die Werte selbst werden von der Kinect Bibliothek berechnet.

#### Intro
Die Intro Klasse ist dafür verantwortlich, die Animation eines Spielers zu steuern. Falls ein Instrument erkannt worden ist, soll die zusammenhängende Animation gestartet (und weitergespielt) werden. Nach einer Zeit ohne eine bestimmte Erkennung, muss die Animation für die Sphäre gespielt werden.
Um das Verhalten zu realisieren, hat die Klasse einen Zähler “_confidenceThreshold”, der bei der Erkennung eines (beliebigen) Instruments auf Null gesetzt wird, oder andernfalls inkrementiert wird. Sobald der Zähler den Wert 120 überschreitet (d.h. 120 Frames sind vorbei ohne Erkennung eines Instruments), wird wieder die Animation der Sphäre gestartet.
“Erkennung” bedeutet, dass die Kinect eine Geste mit einer Konfidenz über 50% detektiert. Es wird das Instrument ausgewählt, dessen Geste den höchsten Konfidenzwert (mind. 50%) hat. Die Konfidenzwerte werden von der GestureSourceManager geliefert.
Nach 30s ohne Erkennung von Gesten, wird die Startszene aufgerufen (d.h. das Spiel wird neu gestartet).

#### GestureSourceManagerDetector
GestureSourceManagerDetector erkennt die Anzahl der Spieler in einer bestimmten Zeitperiode (10s) und startet die entsprechende Szene für die beim Ablauf der gegeben Zeit aktiven Spieler.

#### Gestures
Das Gestures Enum enthält die Namen der Instrumente.

#### Sountrack
Die Klasse Soundtrack spielt die Musik und steuert die Lautstärke für die Instrumente. Instrumente, die erkannt werden, werden lauter gespielt.

#### Kinect API
Um Daten von der Kinect zu bekommen, wird die Kinect API verwendet. Die relevanten Klassen, die verwendet werden sind: 
KinectSensor, um das Gerät selbst zu verwalten
VisualGestureBuilderFrameReader, um Frames von der Kinect zu bekommen
VisualGestureBuilderFrameSource, liefert VisualGestureBuilderFrameReader Objekte
BodySourceManager, erkennt die Körper der Spieler
VisualGestureBuilderDatabase, Ort an dem die Gesten gespeichert sind.

#### Build
Beim Build ist zu beachten, dass alle beteiligten Szenen Teil des Builds sind und dass die Szene “Start” die erste (ID: 0) ist.
Die Erkenner Datenbank z.B. “toccarion_erwachsen.gbd” muss in den Ordner des Builds kopiert werden, damit sie vom GestureSourceManager gefunden wird. 

